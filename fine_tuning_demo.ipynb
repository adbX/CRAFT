{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5JqrpJWoNaB"
   },
   "source": [
    "# CRAFT fine-tuning and inference interactive demo\n",
    "\n",
    "This example notebook shows how to fine-tune a pretrained CRAFT conversational model for the task of forecasting conversational derailment, as shown in the \"Trouble on the Horizon\" paper (note however that due to nondeterminism in the training process, the results will not exactly reproduce the ones shown in the paper; if you need the exact inference results from the paper, see our [online demo](https://colab.research.google.com/drive/1GvICZN0VwZQSWw3pJaEVY-EQGoO-L5lH) that does inference only using the saved already-fine-tuned model from the paper).\n",
    "\n",
    "Also note that this notebook is written primarily for the Wikipedia data. It will still work on the Reddit CMV data as well, but be aware that if seeking to compare results to those in the paper, the actual Reddit CMV evaluation contains some nuances that are not present in the Wikipedia data, as detailed in the [CMV version of the online demo](https://colab.research.google.com/drive/1aGBUBeiF3jT-GtBU9SDUoxhsjwKZaMKl?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "RHkNojY7tzAh",
    "outputId": "a9d10e05-c6db-401f-a651-20bb60a3c095"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries, including convokit\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import unicodedata\n",
    "import itertools\n",
    "from convokit import download, Corpus\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# import all configuration variables\n",
    "from model.config import *\n",
    "# import data preprocessing functions\n",
    "from model.data import *\n",
    "# import our custom PyTorch modules\n",
    "from model.model import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "save_dir = os.path.join(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_w8yFiXuCpg"
   },
   "source": [
    "## Part 1: set up data preprocessing utilities\n",
    "\n",
    "We begin by setting up some helper functions for preprocessing the ConvoKit Utterance data for use with CRAFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0SazSyux7KFS"
   },
   "outputs": [],
   "source": [
    "# Given a ConvoKit conversation, preprocess each utterance's text by tokenizing and truncating.\n",
    "# Returns the processed dialog entry where text has been replaced with a list of\n",
    "# tokens, each no longer than MAX_LENGTH - 1 (to leave space for the EOS token)\n",
    "def processDialog(voc, dialog):\n",
    "    processed = []\n",
    "    for utterance in dialog.iter_utterances():\n",
    "        # skip the section header, which does not contain conversational content\n",
    "        if corpus_name == 'wikiconv' and utterance.meta['is_section_header']:\n",
    "            continue\n",
    "        tokens = tokenize(utterance.text)\n",
    "        # replace out-of-vocabulary tokens\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] not in voc.word2index:\n",
    "                tokens[i] = \"UNK\"\n",
    "        processed.append({\"tokens\": tokens, \"is_attack\": int(utterance.meta[utt_label_metadata]) if utt_label_metadata is not None else 0, \"id\": utterance.id})\n",
    "    if utt_label_metadata is None:\n",
    "        # if the dataset does not come with utterance-level labels, we assume that (as in the case of CMV)\n",
    "        # the only labels are conversation-level and that the actual toxic comment was not included in the\n",
    "        # data. In that case, we must add a dummy comment containing no actual text, to get CRAFT to run on \n",
    "        # the context preceding the dummy (that is, the full prefix before the removed comment)\n",
    "        processed.append({\"tokens\": [\"UNK\"], \"is_attack\": int(dialog.meta[label_metadata]), \"id\": processed[-1][\"id\"] + \"_dummyreply\"})\n",
    "    return processed\n",
    "\n",
    "# Load context-reply pairs from the Corpus, optionally filtering to only conversations\n",
    "# from the specified split (train, val, or test).\n",
    "# Each conversation, which has N comments (not including the section header) will\n",
    "# get converted into N-1 comment-reply pairs, one pair for each reply \n",
    "# (the first comment does not reply to anything).\n",
    "# Each comment-reply pair is a tuple consisting of the conversational context\n",
    "# (that is, all comments prior to the reply), the reply itself, the label (that\n",
    "# is, whether the reply contained a derailment event), and the comment ID of the\n",
    "# last comment in the context (for later use in re-joining with the ConvoKit corpus).\n",
    "# The function returns a list of such pairs.\n",
    "def loadPairs(voc, corpus, split=None, last_only=False):\n",
    "    pairs = []\n",
    "    for convo in corpus.iter_conversations():\n",
    "        # consider only conversations in the specified split of the data\n",
    "        if split is None or convo.meta['split'] == split:\n",
    "            dialog = processDialog(voc, convo)\n",
    "            iter_range = range(1, len(dialog)) if not last_only else [len(dialog)-1]\n",
    "            for idx in iter_range:\n",
    "                reply = dialog[idx][\"tokens\"][:(MAX_LENGTH-1)]\n",
    "                label = dialog[idx][\"is_attack\"]\n",
    "                # when re-joining with the corpus we want to store forecasts in\n",
    "                # the last comment of each context (i.e. the comment directly\n",
    "                # preceding the reply), so we must save that comment ID.\n",
    "                comment_id = dialog[idx-1][\"id\"]\n",
    "                # gather as context up to CONTEXT_SIZE utterances preceding the reply\n",
    "                start = max(idx - CONTEXT_SIZE, 0)\n",
    "                context = [u[\"tokens\"][:(MAX_LENGTH-1)] for u in dialog[start:idx]]\n",
    "                pairs.append((context, reply, label, comment_id))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_ev-7g-xsGQ"
   },
   "source": [
    "## Part 2: load the data\n",
    "\n",
    "Now we load the labeled corpus (Wikiconv or Reddit CMV) from ConvoKit, and run some transformations to prepare it for use with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Y96SXcp4x1yj",
    "outputId": "64557a00-453c-44c0-f334-b5ae83508231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading conversations-gone-awry-corpus to /Users/adb/.convokit/saved-corpora/conversations-gone-awry-corpus\n",
      "Downloading conversations-gone-awry-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/conversations-gone-awry-corpus/conversations-gone-awry-corpus.zip (45.2MB)... Done\n"
     ]
    }
   ],
   "source": [
    "if corpus_name == \"wikiconv\":\n",
    "    corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))\n",
    "elif corpus_name == \"cmv\":\n",
    "    corpus = Corpus(filename=download(\"conversations-gone-awry-cmv-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "fPySt5a4yLId",
    "outputId": "18931f88-572d-4c39-e5da-df3eca9c078c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30021\n",
      "8069\n",
      "4188\n"
     ]
    }
   ],
   "source": [
    "# let's check some quick stats to verify that the corpus loaded correctly\n",
    "print(len(corpus.get_utterance_ids()))\n",
    "print(len(corpus.get_speaker_ids()))\n",
    "print(len(corpus.get_conversation_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "eeNfs0A-yosu",
    "outputId": "61b9f041-d59f-4f5a-a65b-ce9631c02336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'obj_type': 'conversation', '_owner': <convokit.model.corpus.Corpus object at 0x30f5e17d0>, '_id': '146743638.12652.12652', 'vectors': [], '_meta': ConvoKitMeta({'page_title': 'User talk:2005', 'page_id': 1003212, 'pair_id': '143890867.11926.11926', 'conversation_has_personal_attack': False, 'verified': True, 'pair_verified': True, 'annotation_year': '2018', 'split': 'train'}), '_utterance_ids': ['146743638.12652.12652', '146743638.12667.12652', '146842219.12874.12874', '146860774.13072.13072'], '_speaker_ids': None, 'tree': None}\n",
      "Utterance(id: '146743638.12652.12652', conversation_id: 146743638.12652.12652, reply-to: None, speaker: Speaker(id: 'Sirex98', vectors: [], meta: ConvoKitMeta({})), timestamp: 1185295934.0, text: '== [WIKI_LINK: WP:COMMONNAME] ==\\n', vectors: [], meta: ConvoKitMeta({'is_section_header': True, 'comment_has_personal_attack': False, 'toxicity': 0, 'parsed': [{'rt': 3, 'toks': [{'tok': '=', 'tag': 'NFP', 'dep': 'punct', 'up': 3, 'dn': []}, {'tok': '=', 'tag': 'LS', 'dep': 'punct', 'up': 3, 'dn': []}, {'tok': '[', 'tag': '-LRB-', 'dep': 'punct', 'up': 3, 'dn': []}, {'tok': 'WIKI_LINK', 'tag': 'JJ', 'dep': 'ROOT', 'dn': [0, 1, 2, 4]}, {'tok': ':', 'tag': ':', 'dep': 'punct', 'up': 3, 'dn': []}]}, {'rt': 0, 'toks': [{'tok': 'WP', 'tag': 'NNP', 'dep': 'ROOT', 'dn': [1, 2, 5]}, {'tok': ':', 'tag': ':', 'dep': 'punct', 'up': 0, 'dn': []}, {'tok': 'COMMONNAME', 'tag': 'NNPS', 'dep': 'appos', 'up': 0, 'dn': [3]}, {'tok': ']', 'tag': '-RRB-', 'dep': 'punct', 'up': 2, 'dn': []}, {'tok': '=', 'tag': 'SYM', 'dep': 'punct', 'up': 5, 'dn': []}, {'tok': '=', 'tag': 'SYM', 'dep': 'punct', 'up': 0, 'dn': [4, 6]}, {'tok': '\\n', 'tag': '', 'dep': '', 'up': 5, 'dn': []}]}]}))\n"
     ]
    }
   ],
   "source": [
    "# Let's also take a look at some example data to see what kinds of information/metadata are available to us\n",
    "print(list(corpus.iter_conversations())[0].__dict__)\n",
    "print(list(corpus.iter_utterances())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3QIoTtbzOfY"
   },
   "source": [
    "Now we can use the utilities defined in Part 1 to convert the ConvoKit conversational data into a tokenized form that can be straightforwardly turned into Tensors later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WlpbT72FxK8W"
   },
   "outputs": [],
   "source": [
    "# First, we need to build the vocabulary so that we know how to map tokens to tensor indicies.\n",
    "# For the sake of replicating the paper results, we will load the pre-computed vocabulary objects used in the paper.\n",
    "voc = loadPrecomputedVoc(corpus_name, word2index_path, index2word_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "eRSAVrgSxhmD",
    "outputId": "a682ac56-5ec9-4a88-fdce-fc9fb08aa104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50004\n",
      "[('UNK', 3), ('.', 4), ('the', 5), (\"'\", 6), (',', 7), ('to', 8), ('i', 9), ('of', 10), ('a', 11), ('and', 12)]\n",
      "[('0', 'PAD'), ('1', 'SOS'), ('2', 'EOS'), ('3', 'UNK'), ('4', '.'), ('5', 'the'), ('6', \"'\"), ('7', ','), ('8', 'to'), ('9', 'i')]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the Voc object to make sure it loaded correctly\n",
    "print(voc.num_words) # expected vocab size is 50004: it was built using a fixed vocab size of 50k plus 4 spots for special tokens PAD, SOS, EOS, and UNK.\n",
    "print(list(voc.word2index.items())[:10])\n",
    "print(list(voc.index2word.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pmaWfn7vyTjy"
   },
   "outputs": [],
   "source": [
    "# Convert the test set data into a list of input/label pairs. Each input will represent the conversation as a list of lists of tokens.\n",
    "train_pairs = loadPairs(voc, corpus, \"train\", last_only=True)\n",
    "val_pairs = loadPairs(voc, corpus, \"val\", last_only=True)\n",
    "test_pairs = loadPairs(voc, corpus, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "RIiQNvg4zBEi",
    "outputId": "11d7b50b-bc00-4080-d4ce-9294b3988194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2508\n",
      "840\n",
      "4365\n",
      "([['i', 'notice', 'that', 'UNK', 'that', 'moved', 'UNK', 'to', 'bill', 'chen', 'citing', 'UNK', ',', 'then', 'you', 'reverted', 'this', 'change', ',', 'bill', 'chen', 'doesn', \"'\", 't', 'commonly', 'go', 'by', 'william', ',', 'his', 'book', 'is', 'even', 'penned', 'as', 'bill', 'chen', '.', 'from', 'what', 'i', 'read', 'in', 'wp', ':', 'commonname', 'UNK', 'seems', 'to', 'be', 'correct', ',', 'examples', 'given', 'are', 'names', 'such', 'as', ':', '*', 'UNK', '(', 'not', 'UNK', ')', '*', 'UNK', '(', 'not', 'UNK', ')', 'i', 'think', 'this', 'revert', 'may', 'have', 'been', 'a'], ['chen', 'was', 'known', 'in', 'the', 'poker', 'world', 'as', '\"', 'william', '\"', 'for', 'years', 'before', 'he', 'became', 'commonly', 'known', 'as', '\"', 'bill', '\"', '.', 'i', 'changed', 'it', 'back', 'because', 'incidences', 'online', 'including', 'usenet', 'are', 'roughly', 'equal', ',', 'nothing', 'at', 'all', 'like', 'bill', 'clinton', 'and', 'william', 'clinton', ',', 'and', 'in', 'equal', 'cases', 'using', 'the', 'real', 'name', 'seems', 'the', 'best', 'choice', '.', '(', 'the', 'UNK', 'page', 'is', 'especially', 'UNK', '.', '.', '.', 'UNK', 'in', 'the', 'page', 'title', ',', 'bill', 'in', 'the', 'page']], ['i', 'see', 'what', 'you', 'saying', 'i', 'just', 'read', 'his', 'UNK', 'profile', ',', 'it', 'struck', 'me', 'when', 'i', 'saw', 'the', 'change', 'because', 'i', 'remember', 'him', 'being', 'called', 'bill', 'when', 'i', 'watched', 'the', 'last', 'season', 'of', 'high', 'stakes', 'poker', ',', 'but', 'you', 'seem', 'to', 'have', 'many', 'more', 'years', 'experience', 'in', 'the', 'poker', '/', 'gambling', 'world', 'then', 'i', 'do', '(', 'i', \"'\", 'm', 'still', 'a', 'bit', 'of', 'a', 'newbie', ')', ',', 'so', 'i', 'wanted', 'to', 'check', 'with', 'you', 'first', '.', 'btw', 'as'], 0, '146842219.12874.12874')\n",
      "([['no', 'more', 'than', 'two', 'editors', 'advocated', 'deletion', '.', 'UNK', 'and', 'maybe', 'UNK', '.', 'that', \"'\", 's', 'not', 'a', 'clear', 'consensus', 'for', 'deletion', '.', 'cheers', ','], ['in', 'the', 'future', 'please', 'don', \"'\", 't', 'close', 'afds', 'when', 'you', 'don', \"'\", 't', 'have', 'the', 'courtesy', 'of', 'reading', 'the', 'comments', '.', 'all', 'comments', 'favored', 'deletion', 'except', 'two', '.', 'please', 'don', \"'\", 't', 'be', 'so', 'careless', 'in', 'the', 'future', '.'], ['that', 'simply', 'isn', \"'\", 't', 'true', '.', 'if', 'you', 'read', 'the', 'comments', ',', 'you', \"'\", 'll', 'find', 'it', \"'\", 's', 'actually', '2', 'keep', ',', '4', 'transwiki', ',', '2', 'delete', '(', 'more', 'or', 'less', ')', '.', 'the', \"'\", \"'\", 'comments', \"'\", \"'\", 'favour', 'no', 'consensus', '/', 'transwiki', '.', 'the', '\"', 'votes', '\"', 'favour', 'delete', ',', 'but', 'voting', 'is', 'evil', ',', 'of', 'course', '.', '.', '.'], ['somehow', ',', 'i', 'suspect', 'you', 'may', 'wish', 'to', 'participate', 'in', 'UNK', 'discussion', '.', 'cheers', ',']], ['i', 'assume', 'your', 'deliberate', 'lying', 'has', 'a', 'point', ',', 'but', 'get', 'over', 'it', '.', 'stop', 'bizarrely', 'goin', 'on', 'about', 'UNK', '.', 'that', 'has', 'nothing', 'to', 'do', 'with', 'the', 'afd', '.', 'there', 'was', 'a', 'plain', 'consensus', 'for', 'deleting', 'the', 'article', '.', 'UNK', 'is', 'completely', 'unrelated', '.', 'please', 'don', \"'\", 't', 'be', 'so', 'deliberately', 'obtuse', 'in', 'the', 'future', '.', 'wasting', 'other', 'people', \"'\", 's', 'time', 'is', 'simply', 'rude', '.'], 1, '144052463.12169.12169')\n",
      "([['if', 'you', 'have', 'problems', 'with', 'my', 'edits', 'to', 'the', 'UNK', 'page', 'please', 'let', 'me', 'know', ',', 'do', 'not', 'just', 'revert', 'the', 'edits', '.', 'although', 'the', 'UNK', 'article', 'is', 'very', 'accurate', 'the', 'introduction', 'is', 'riddled', 'with', 'errors', ',', 'which', 'i', 'corrected', '.', 'i', 'think', 'it', 'is', 'everyone', \"'\", 's', 'best', 'interests', 'to', 'make', 'wiki', 'pages', 'as', 'accurate', 'as', 'possible', 'and', 'the', 'four', 'wheel', 'drive', 'article', 'is', 'not', 'a', 'UNK', 'example', 'of', 'this', '.', 'i', '.', 'e', '.', 'all', '-', 'wheel'], ['*', 'shrug', '*', 'it', '*', 'is', '*', 'just', 'a', 'marketing', 'term', '.', 'i', 'wish', 'you', 'lot', 'would', 'stop', 'editing', 'it', 'otherwise', '.', 'UNK', '.']], ['although', 'UNK', 'can', 'be', 'considered', 'a', 'form', 'of', 'UNK', 'it', 'is', 'not', 'the', 'same', 'drive', 'train', 'type', 'as', 'part', '-', 'time', 'UNK', '.', 'so', 'i', 'would', 'have', 'to', 'say', 'calling', 'it', 'just', 'a', 'marketing', 'term', 'is', 'a', 'narrow', 'minded', 'and', 'inaccurate', 'statement', '.', 'even', 'though', 'they', 'are', 'similar', 'you', 'can', \"'\", 't', 'just', 'UNK', 'them', 'into', 'the', 'same', 'group', '.', 'if', ',', 'as', 'you', 'say', ',', 'UNK', 'is', 'just', 'a', 'marketing', 'term', 'then', 'taking', 'a', 'turn', 'in', 'a', 'audi'], 0, '127331347.862.862')\n",
      "([['please', 'stop', 'removing', 'and', 'altering', 'other', 'editors', \"'\", 'comments', '.', 'what', 'appeared', 'to', 'be', 'valid', 'concern', 'is', 'quickly', 'descending', 'into', 'trolling', ',', 'and', 'if', 'you', 'continue', ',', 'you', 'may', 'be', 'blocked', 'from', 'editing', '.', 'stop', 'it', '.', '-'], ['well', 'please', 'stop', 'posting', 'incorrect', 'information', '.', 'if', 'you', 'were', 'right', 'i', \"'\", 'd', 'agree', 'with', 'you', ',', 'and', 'i', 'am', 'not', 'trolling', '.'], ['UNK', 'is', 'trolling', ',', 'as', 'is', 'removing', 'other', 'people', \"'\", 's', 'comments', '.', 'look', ',', 'wikipedia', 'is', 'built', 'on', 'consensus', ',', 'and', 'consensus', 'has', 'it', 'that', 'we', 'use', 'american', 'style', 'for', 'american', 'subjects', '.', 'end', 'of', 'story', '.', 'any', 'more', 'complaint', 'about', 'trolling', 'about', 'this', 'topic', 'and', 'i', \"'\", 'll', 'report', 'you', 'myself', '.']], ['bullshit', '.', 'i', 'am', 'correcting', 'a', 'simple', 'mistake', '.', 'if', 'i', 'was', 'trolling', 'i', \"'\", 'd', 'be', 'doing', 'damage', 'to', 'the', 'page', ',', 'yet', 'i', 'am', 'not', '.', 'what', 'was', 'written', 'is', 'wrong', ',', 'simple', 'as', 'that', '.', 'all', 'i', 'have', 'done', 'is', 'disagree', 'with', 'what', 'was', 'written', 'and', 'written', 'as', 'such', '.', 'if', 'that', \"'\", 's', 'trolling', 'then', 'you', 'are', 'guilty', 'as', 'well', '.', 'and', 'stop', 'UNK', 'my', 'page', 'dickhead', '.', 'UNK', '.'], 1, '144645147.1375.1330')\n",
      "([['please', 'stop', 'including', 'disreputable', 'sources', 'for', 'this', 'article', '.', 'wikipedia', 'policy', 'is', 'quite', 'clear', 'on', 'this', 'matter', 'blogs', 'and', 'other', 'websites', 'which', 'do', 'not', 'employ', 'editorial', 'oversight', 'of', 'authors', \"'\", 'work', 'are', 'not', 'permitted', 'as', 'sources', 'here', '.', 'please', 'stop', 'adding', 'blogs', '.'], ['please', 'stop', 'deleting', 'reputable', 'sources', 'from', 'this', 'article', '.', 'you', 'have', 'deleted', 'joe', 'wilson', \"'\", 's', 'nyt', 'article', 'that', 'is', 'a', 'key', 'factor', 'in', 'this', 'whole', 'controversy', '!', 'among', 'others', '.', 'simply', 'because', 'the', 'article', 'is', 'printed', 'on', 'a', 'different', 'site', 'does', 'not', 'mean', 'it', 'is', 'sourced', 'to', 'a', '\"', 'heinous', 'blog', '\"', '(', 'which', 'the', 'site', 'is', 'not', 'anyway', ')', '.', 'if', 'you', 'find', 'a', 'better', 'place', 'that', 'the', 'article', 'exists', ',', 'put', 'it', 'there', '.', 'or', 'if'], ['the', 'american', 'prospect', 'article', 'should', 'stay', '-', 'american', 'prospect', 'easily', 'meets', 'UNK', '.', 'the', 'cooperative', 'research', 'project', 'link', 'should', 'be', 'nuked', 'and', 'should', 'stay', 'nuked', '-', 'i', 'see', 'no', 'evidence', 'that', 'it', \"'\", 's', 'a', 'reliable', 'source', '.', 'factcheck', '.', 'org', 'is', 'reliable', 'enough', 'that', 'the', 'vice', 'president', 'of', 'the', 'united', 'states', '(', 'incorrectly', ')', 'cited', 'it', 'in', 'his', 'debate', 'as', 'an', 'authoritative', 'source', ';', 'they', 'have', 'a', 'good', 'reputation', ',', 'and', 'their', 'very', \"'\", \"'\", 'purpose', \"'\", \"'\"], ['agreed', 'UNK', 'cooperative', 'research', 'but', 'not', 'the', 'alternet', 'citation', '-', 'they', 'are', 'transcribing', 'an', 'interview', 'on', 'a', 'well', 'known', 'radio', 'show', 'with', 'a', 'well', 'known', 'source', 'with', 'expertise', 'on', 'this', 'topic', 'whose', 'comments', 'are', 'cited', 'in', 'numerous', 'mainstream', 'sources', '.', 'if', 'you', 'have', 'a', 'better', 'source', 'for', 'the', 'transcript', 'that', 'is', 'fine', 'but', 'you', 'cannot', 'just', 'delete', 'it', 'because', 'it', 'is', '\"', 'edited', '\"', '-', 'unless', 'you', 'have', 'evidence', 'that', 'they', 'are', 'making', 'stuff', 'up', ',', 'we', 'must', 'presume'], ['actually', ',', 'especially', 'with', 'alternet', ',', 'we', \"'\", \"'\", 'can', \"'\", 't', \"'\", \"'\", 'assume', 'good', 'faith', ';', 'we', 'need', 'to', 'do', 'exactly', 'the', 'opposite', '.', 'we', 'need', 'to', 'examine', 'sources', 'critically', ',', 'according', 'to', 'the', 'guidelines', 'on', 'UNK', '.', 'were', 'it', 'to', 'be', 'a', 'verbatim', 'copy', ',', 'perhaps', 'we', 'could', 'accept', 'it', 'as', 'a', 'source', '(', \"'\", \"'\", 'perhaps', \"'\", \"'\", 'being', 'absolutely', 'critical', ')', ',', 'but', 'because', 'it', \"'\", 's', 'edited', 'and', 'doesn', \"'\", 't', 'contain', 'information']], ['(', '1', ')', 'please', 'substantiate', 'that', 'the', 'source', 'is', '\"', 'notoriously', 'unreliable', '.', '\"', '(', '2', ')', 'please', 'indicate', 'where', 'it', 'says', 'we', 'should', 'assume', 'bad', 'faith', 'with', 'sources', 'that', 'are', 'transcripts', 'of', 'interviews', '(', 'i', 'know', 'the', 'quote', 'in', 'the', 'article', 'is', 'directly', 'from', 'the', 'interview', 'as', 'i', 'listened', 'to', 'the', 'interview', 'myself', ';', 'i', 'also', 'have', 'looked', 'at', 'the', 'transcript', 'and', 'do', 'not', 'see', 'anything', 'that', 'is', 'different', 'from', 'what', 'i', 'heard', ';', 'but', 'apparently', 'i', 'should'], 0, '67175218.24895.24895')\n"
     ]
    }
   ],
   "source": [
    "# Validate the conversion by checking data size and some samples\n",
    "print(len(train_pairs))\n",
    "print(len(val_pairs))\n",
    "print(len(test_pairs))\n",
    "for p in train_pairs[:5]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghTVeRFK0CUe"
   },
   "source": [
    "## Part 3: define the inference pipeline\n",
    "\n",
    "CRAFT inference consists of three steps: (1) using the utterance encoder to produce embeddings of each comment in the context (2) running the comment embeddings through the context encoder to get a final representation of conversational context (3) running the classifier head on the context embedding. To streamline the subsequent code, we encapsulate these three steps in a single PyTorch `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZzAgSRKi0p_I"
   },
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    \"\"\"This helper module encapsulates the CRAFT pipeline, defining the logic of passing an input through each consecutive sub-module.\"\"\"\n",
    "    def __init__(self, encoder, context_encoder, classifier):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.context_encoder = context_encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length):\n",
    "        # Forward input through encoder model\n",
    "        _, utt_encoder_hidden = self.encoder(input_batch, utt_lengths)\n",
    "        \n",
    "        # Convert utterance encoder final states to batched dialogs for use by context encoder\n",
    "        context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)\n",
    "        \n",
    "        # Forward pass through context encoder\n",
    "        context_encoder_outputs, context_encoder_hidden = self.context_encoder(context_encoder_input, dialog_lengths)\n",
    "        \n",
    "        # Forward pass through classifier to get prediction logits\n",
    "        logits = self.classifier(context_encoder_outputs, dialog_lengths)\n",
    "        \n",
    "        # Apply sigmoid activation\n",
    "        predictions = F.sigmoid(logits)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjC1hgIWGl7g"
   },
   "source": [
    "## Part 4: define training loop\n",
    "\n",
    "Now that we have all the model components defined, we need to define the actual training procedure. This will be a fairly standard neural network training loop, iterating over batches of labeled dialogs and computing cross-entropy loss on the predicted label. We will also define evaluation functions so that we can compute accuracy on the validation set after every epoch, allowing us to keep the model with the best validation performance. Note that for the sake of simpler code, validation accuracy is computed in the \"unfair\" manner using a single run of CRAFT over the full context preceding the actual personal attack, rather than the more realistic (and complicated) iterated evaluation that is used for final evaluation of the test set (in practice the two metrics track each other fairly well, making this a reasonable simplification for the sake of easy validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zIAHOvcdHR_h"
   },
   "outputs": [],
   "source": [
    "def train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments\n",
    "          encoder, context_encoder, attack_clf,                                                                    # network arguments\n",
    "          encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments\n",
    "          batch_size, clip, max_length=MAX_LENGTH):                                                                # misc arguments\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    context_encoder_optimizer.zero_grad()\n",
    "    attack_clf_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    dialog_lengths = dialog_lengths.to(device)\n",
    "    utt_lengths = utt_lengths.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward pass through utterance encoder\n",
    "    _, utt_encoder_hidden = encoder(input_variable, utt_lengths)\n",
    "    \n",
    "    # Convert utterance encoder final states to batched dialogs for use by context encoder\n",
    "    context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)\n",
    "    \n",
    "    # Forward pass through context encoder\n",
    "    context_encoder_outputs, _ = context_encoder(context_encoder_input, dialog_lengths)\n",
    "\n",
    "    # Forward pass through classifier to get prediction logits\n",
    "    logits = attack_clf(context_encoder_outputs, dialog_lengths)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(context_encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(attack_clf.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    context_encoder_optimizer.step()\n",
    "    attack_clf_optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluateBatch(encoder, context_encoder, predictor, voc, input_batch, dialog_lengths, \n",
    "                  dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, device, max_length=MAX_LENGTH):\n",
    "    # Set device options\n",
    "    input_batch = input_batch.to(device)\n",
    "    dialog_lengths = dialog_lengths.to(device)\n",
    "    utt_lengths = utt_lengths.to(device)\n",
    "    # Predict future attack using predictor\n",
    "    scores = predictor(input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length)\n",
    "    predictions = (scores > 0.5).float()\n",
    "    return predictions, scores\n",
    "\n",
    "def validate(dataset, encoder, context_encoder, predictor, voc, batch_size, device):\n",
    "    # create a batch iterator for the given data\n",
    "    batch_iterator = batchIterator(voc, dataset, batch_size, shuffle=False)\n",
    "    # find out how many iterations we will need to cover the whole dataset\n",
    "    n_iters = len(dataset) // batch_size + int(len(dataset) % batch_size > 0)\n",
    "    # containers for full prediction results so we can compute accuracy at the end\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for iteration in range(1, n_iters+1):\n",
    "        batch, batch_dialogs, _, true_batch_size = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len = batch\n",
    "        dialog_lengths_list = [len(x) for x in batch_dialogs]\n",
    "        # run the model\n",
    "        predictions, scores = evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,\n",
    "                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices,\n",
    "                                            true_batch_size, device)\n",
    "        # aggregate results for computing accuracy at the end\n",
    "        all_preds += [p.item() for p in predictions]\n",
    "        all_labels += [l.item() for l in labels]\n",
    "        print(\"Iteration: {}; Percent complete: {:.1f}%\".format(iteration, iteration / n_iters * 100))\n",
    "\n",
    "    # compute and return the accuracy\n",
    "    return (np.asarray(all_preds) == np.asarray(all_labels)).mean()\n",
    "\n",
    "def trainIters(voc, pairs, val_pairs, encoder, context_encoder, attack_clf,\n",
    "               encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,\n",
    "               n_iteration, batch_size, print_every, validate_every, clip):\n",
    "    \n",
    "    # create a batch iterator for training data\n",
    "    batch_iterator = batchIterator(voc, pairs, batch_size)\n",
    "    \n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    # keep track of best validation accuracy - only save when we have a model that beats the current best\n",
    "    best_acc = 0\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch, training_dialogs, _, true_batch_size = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, _, target_variable, mask, max_target_len = training_batch\n",
    "        dialog_lengths_list = [len(x) for x in training_dialogs]\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments\n",
    "                     encoder, context_encoder, attack_clf,                                                                    # network arguments\n",
    "                     encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments\n",
    "                     true_batch_size, clip)                                                                                   # misc arguments\n",
    "        print_loss += loss\n",
    "        \n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        if (iteration % validate_every == 0):\n",
    "            print(\"Validating!\")\n",
    "            # put the network components into evaluation mode\n",
    "            encoder.eval()\n",
    "            context_encoder.eval()\n",
    "            attack_clf.eval()\n",
    "            \n",
    "            predictor = Predictor(encoder, context_encoder, attack_clf)\n",
    "            accuracy = validate(val_pairs, encoder, context_encoder, predictor, voc, batch_size, device)\n",
    "            print(\"Validation set accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "            # keep track of our best model so far\n",
    "            if accuracy > best_acc:\n",
    "                print(\"Validation accuracy better than current best; saving model...\")\n",
    "                best_acc = accuracy\n",
    "                torch.save({\n",
    "                    'iteration': iteration,\n",
    "                    'en': encoder.state_dict(),\n",
    "                    'ctx': context_encoder.state_dict(),\n",
    "                    'atk_clf': attack_clf.state_dict(),\n",
    "                    'en_opt': encoder_optimizer.state_dict(),\n",
    "                    'ctx_opt': context_encoder_optimizer.state_dict(),\n",
    "                    'atk_clf_opt': attack_clf_optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    'voc_dict': voc.__dict__,\n",
    "                    'embedding': embedding.state_dict()\n",
    "                }, os.path.join(save_dir, \"finetuned_model.tar\"))\n",
    "            \n",
    "            # put the network components back into training mode\n",
    "            encoder.train()\n",
    "            context_encoder.train()\n",
    "            attack_clf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eG1p_cH5fw9"
   },
   "source": [
    "## Part 5: define the evaluation procedure\n",
    "\n",
    "We're almost ready to run! The last component we need is some code to evaluate performance on the test set after fine-tuning is completed. This evaluation should use the full iterative procedure described in the paper, replicating how a system might be deployed in practice, without knowledge of where the personal attack occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yZqEcwEJ5bqn"
   },
   "outputs": [],
   "source": [
    "def evaluateDataset(dataset, encoder, context_encoder, predictor, voc, batch_size, device):\n",
    "    # create a batch iterator for the given data\n",
    "    batch_iterator = batchIterator(voc, dataset, batch_size, shuffle=False)\n",
    "    # find out how many iterations we will need to cover the whole dataset\n",
    "    n_iters = len(dataset) // batch_size + int(len(dataset) % batch_size > 0)\n",
    "    output_df = {\n",
    "        \"id\": [],\n",
    "        \"prediction\": [],\n",
    "        \"score\": []\n",
    "    }\n",
    "    for iteration in range(1, n_iters+1):\n",
    "        batch, batch_dialogs, _, true_batch_size = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len = batch\n",
    "        dialog_lengths_list = [len(x) for x in batch_dialogs]\n",
    "        # run the model\n",
    "        predictions, scores = evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,\n",
    "                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices,\n",
    "                                            true_batch_size, device)\n",
    "\n",
    "        # format the output as a dataframe (which we can later re-join with the corpus)\n",
    "        for i in range(true_batch_size):\n",
    "            convo_id = convo_ids[i]\n",
    "            pred = predictions[i].item()\n",
    "            score = scores[i].item()\n",
    "            output_df[\"id\"].append(convo_id)\n",
    "            output_df[\"prediction\"].append(pred)\n",
    "            output_df[\"score\"].append(score)\n",
    "                \n",
    "        print(\"Iteration: {}; Percent complete: {:.1f}%\".format(iteration, iteration / n_iters * 100))\n",
    "\n",
    "    return pd.DataFrame(output_df).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0VIv8sbOaB6"
   },
   "source": [
    "## Part 6: build and fine-tune the model\n",
    "\n",
    "We finally have all the components we need! Now we can instantiate the CRAFT model components, load the pre-trained weights, and run fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n",
      "Iteration: 1; Percent complete: 1.4%\n",
      "Iteration: 2; Percent complete: 2.9%\n",
      "Iteration: 3; Percent complete: 4.3%\n",
      "Iteration: 4; Percent complete: 5.8%\n",
      "Iteration: 5; Percent complete: 7.2%\n",
      "Iteration: 6; Percent complete: 8.7%\n",
      "Iteration: 7; Percent complete: 10.1%\n",
      "Iteration: 8; Percent complete: 11.6%\n",
      "Iteration: 9; Percent complete: 13.0%\n",
      "Iteration: 10; Percent complete: 14.5%\n",
      "Iteration: 11; Percent complete: 15.9%\n",
      "Iteration: 12; Percent complete: 17.4%\n",
      "Iteration: 13; Percent complete: 18.8%\n",
      "Iteration: 14; Percent complete: 20.3%\n",
      "Iteration: 15; Percent complete: 21.7%\n",
      "Iteration: 16; Percent complete: 23.2%\n",
      "Iteration: 17; Percent complete: 24.6%\n",
      "Iteration: 18; Percent complete: 26.1%\n",
      "Iteration: 19; Percent complete: 27.5%\n",
      "Iteration: 20; Percent complete: 29.0%\n",
      "Iteration: 21; Percent complete: 30.4%\n",
      "Iteration: 22; Percent complete: 31.9%\n",
      "Iteration: 23; Percent complete: 33.3%\n",
      "Iteration: 24; Percent complete: 34.8%\n",
      "Iteration: 25; Percent complete: 36.2%\n",
      "Iteration: 26; Percent complete: 37.7%\n",
      "Iteration: 27; Percent complete: 39.1%\n",
      "Iteration: 28; Percent complete: 40.6%\n",
      "Iteration: 29; Percent complete: 42.0%\n",
      "Iteration: 30; Percent complete: 43.5%\n",
      "Iteration: 31; Percent complete: 44.9%\n",
      "Iteration: 32; Percent complete: 46.4%\n",
      "Iteration: 33; Percent complete: 47.8%\n",
      "Iteration: 34; Percent complete: 49.3%\n",
      "Iteration: 35; Percent complete: 50.7%\n",
      "Iteration: 36; Percent complete: 52.2%\n",
      "Iteration: 37; Percent complete: 53.6%\n",
      "Iteration: 38; Percent complete: 55.1%\n",
      "Iteration: 39; Percent complete: 56.5%\n",
      "Iteration: 40; Percent complete: 58.0%\n",
      "Iteration: 41; Percent complete: 59.4%\n",
      "Iteration: 42; Percent complete: 60.9%\n",
      "Iteration: 43; Percent complete: 62.3%\n",
      "Iteration: 44; Percent complete: 63.8%\n",
      "Iteration: 45; Percent complete: 65.2%\n",
      "Iteration: 46; Percent complete: 66.7%\n",
      "Iteration: 47; Percent complete: 68.1%\n",
      "Iteration: 48; Percent complete: 69.6%\n",
      "Iteration: 49; Percent complete: 71.0%\n",
      "Iteration: 50; Percent complete: 72.5%\n",
      "Iteration: 51; Percent complete: 73.9%\n",
      "Iteration: 52; Percent complete: 75.4%\n",
      "Iteration: 53; Percent complete: 76.8%\n",
      "Iteration: 54; Percent complete: 78.3%\n",
      "Iteration: 55; Percent complete: 79.7%\n",
      "Iteration: 56; Percent complete: 81.2%\n",
      "Iteration: 57; Percent complete: 82.6%\n",
      "Iteration: 58; Percent complete: 84.1%\n",
      "Iteration: 59; Percent complete: 85.5%\n",
      "Iteration: 60; Percent complete: 87.0%\n",
      "Iteration: 61; Percent complete: 88.4%\n",
      "Iteration: 62; Percent complete: 89.9%\n",
      "Iteration: 63; Percent complete: 91.3%\n",
      "Iteration: 64; Percent complete: 92.8%\n",
      "Iteration: 65; Percent complete: 94.2%\n",
      "Iteration: 66; Percent complete: 95.7%\n",
      "Iteration: 67; Percent complete: 97.1%\n",
      "Iteration: 68; Percent complete: 98.6%\n",
      "Iteration: 69; Percent complete: 100.0%\n"
     ]
    }
   ],
   "source": [
    "MODEL_URL = \"http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/craft_full.tar\"\n",
    "\n",
    "# Fix random state for reproducibility\n",
    "random.seed(2019)\n",
    "\n",
    "# Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(\"Loading saved parameters...\")\n",
    "if not os.path.isfile(\"model.tar\"):\n",
    "    print(\"\\tDownloading trained CRAFT...\")\n",
    "    urlretrieve(MODEL_URL, \"model.tar\")\n",
    "    print(\"\\t...Done!\")\n",
    "# checkpoint = torch.load(\"model.tar\")\n",
    "# If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.\n",
    "# To do so, replace the previous line with the following:\n",
    "checkpoint = torch.load(\"model.tar\", map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "context_sd = checkpoint['ctx']\n",
    "attack_clf_sd = checkpoint['atk_clf']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoders, decoder, and classifier...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# Initialize utterance and context encoders\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "context_encoder = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_encoder.load_state_dict(context_sd)\n",
    "# Initialize classifier\n",
    "attack_clf = SingleTargetClf(hidden_size, dropout)\n",
    "attack_clf.load_state_dict(attack_clf_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "context_encoder = context_encoder.to(device)\n",
    "attack_clf = attack_clf.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "context_encoder.eval()\n",
    "attack_clf.eval()\n",
    "\n",
    "# Initialize the pipeline\n",
    "predictor = Predictor(encoder, context_encoder, attack_clf)\n",
    "\n",
    "# Run the pipeline!\n",
    "forecasts_df = evaluateDataset(test_pairs, encoder, context_encoder, predictor, voc, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4QRinW10Oo_G",
    "outputId": "99df8b29-f6cb-4fab-80db-611e73ab3869",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n",
      "Building optimizers...\n",
      "Starting Training!\n",
      "Will train for 1170 iterations\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 10; Percent complete: 0.9%; Average loss: 0.6849\n",
      "Iteration: 20; Percent complete: 1.7%; Average loss: 0.6828\n",
      "Iteration: 30; Percent complete: 2.6%; Average loss: 0.6761\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 60.48%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 40; Percent complete: 3.4%; Average loss: 0.6651\n",
      "Iteration: 50; Percent complete: 4.3%; Average loss: 0.6569\n",
      "Iteration: 60; Percent complete: 5.1%; Average loss: 0.6576\n",
      "Iteration: 70; Percent complete: 6.0%; Average loss: 0.6466\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.57%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 80; Percent complete: 6.8%; Average loss: 0.6368\n",
      "Iteration: 90; Percent complete: 7.7%; Average loss: 0.6245\n",
      "Iteration: 100; Percent complete: 8.5%; Average loss: 0.6144\n",
      "Iteration: 110; Percent complete: 9.4%; Average loss: 0.6023\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.45%\n",
      "Iteration: 120; Percent complete: 10.3%; Average loss: 0.5944\n",
      "Iteration: 130; Percent complete: 11.1%; Average loss: 0.5802\n",
      "Iteration: 140; Percent complete: 12.0%; Average loss: 0.5593\n",
      "Iteration: 150; Percent complete: 12.8%; Average loss: 0.5430\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.21%\n",
      "Iteration: 160; Percent complete: 13.7%; Average loss: 0.5335\n",
      "Iteration: 170; Percent complete: 14.5%; Average loss: 0.5186\n",
      "Iteration: 180; Percent complete: 15.4%; Average loss: 0.4965\n",
      "Iteration: 190; Percent complete: 16.2%; Average loss: 0.4882\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.93%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 200; Percent complete: 17.1%; Average loss: 0.4699\n",
      "Iteration: 210; Percent complete: 17.9%; Average loss: 0.4472\n",
      "Iteration: 220; Percent complete: 18.8%; Average loss: 0.4379\n",
      "Iteration: 230; Percent complete: 19.7%; Average loss: 0.4388\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 64.52%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 240; Percent complete: 20.5%; Average loss: 0.4170\n",
      "Iteration: 250; Percent complete: 21.4%; Average loss: 0.3898\n",
      "Iteration: 260; Percent complete: 22.2%; Average loss: 0.3951\n",
      "Iteration: 270; Percent complete: 23.1%; Average loss: 0.3852\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 64.29%\n",
      "Iteration: 280; Percent complete: 23.9%; Average loss: 0.3765\n",
      "Iteration: 290; Percent complete: 24.8%; Average loss: 0.3669\n",
      "Iteration: 300; Percent complete: 25.6%; Average loss: 0.3287\n",
      "Iteration: 310; Percent complete: 26.5%; Average loss: 0.3354\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.21%\n",
      "Iteration: 320; Percent complete: 27.4%; Average loss: 0.3664\n",
      "Iteration: 330; Percent complete: 28.2%; Average loss: 0.3016\n",
      "Iteration: 340; Percent complete: 29.1%; Average loss: 0.3239\n",
      "Iteration: 350; Percent complete: 29.9%; Average loss: 0.2866\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 64.05%\n",
      "Iteration: 360; Percent complete: 30.8%; Average loss: 0.3080\n",
      "Iteration: 370; Percent complete: 31.6%; Average loss: 0.2643\n",
      "Iteration: 380; Percent complete: 32.5%; Average loss: 0.2774\n",
      "Iteration: 390; Percent complete: 33.3%; Average loss: 0.2628\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.69%\n",
      "Iteration: 400; Percent complete: 34.2%; Average loss: 0.2702\n",
      "Iteration: 410; Percent complete: 35.0%; Average loss: 0.2531\n",
      "Iteration: 420; Percent complete: 35.9%; Average loss: 0.2424\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.10%\n",
      "Iteration: 430; Percent complete: 36.8%; Average loss: 0.2004\n",
      "Iteration: 440; Percent complete: 37.6%; Average loss: 0.2360\n",
      "Iteration: 450; Percent complete: 38.5%; Average loss: 0.2043\n",
      "Iteration: 460; Percent complete: 39.3%; Average loss: 0.2179\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.21%\n",
      "Iteration: 470; Percent complete: 40.2%; Average loss: 0.1937\n",
      "Iteration: 480; Percent complete: 41.0%; Average loss: 0.1788\n",
      "Iteration: 490; Percent complete: 41.9%; Average loss: 0.1696\n",
      "Iteration: 500; Percent complete: 42.7%; Average loss: 0.1738\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.21%\n",
      "Iteration: 510; Percent complete: 43.6%; Average loss: 0.1740\n",
      "Iteration: 520; Percent complete: 44.4%; Average loss: 0.1726\n",
      "Iteration: 530; Percent complete: 45.3%; Average loss: 0.1478\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Training!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWill train for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m iterations\u001b[39m\u001b[33m\"\u001b[39m.format(n_iteration))\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mtrainIters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m           \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_encoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_clf_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m           \u001b[49m\u001b[43mn_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mtrainIters\u001b[39m\u001b[34m(voc, pairs, val_pairs, encoder, context_encoder, attack_clf, encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding, n_iteration, batch_size, print_every, validate_every, clip)\u001b[39m\n\u001b[32m    103\u001b[39m dialog_lengths_list = [\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m training_dialogs]\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# Run a training iteration with batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialog_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialog_lengths_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutt_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialog_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# input/output arguments\u001b[39;49;00m\n\u001b[32m    107\u001b[39m \u001b[43m             \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                                                    \u001b[49m\u001b[38;5;66;43;03m# network arguments\u001b[39;49;00m\n\u001b[32m    108\u001b[39m \u001b[43m             \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_encoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_clf_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                      \u001b[49m\u001b[38;5;66;43;03m# optimization arguments\u001b[39;49;00m\n\u001b[32m    109\u001b[39m \u001b[43m             \u001b[49m\u001b[43mtrue_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m                                                                                   \u001b[38;5;66;03m# misc arguments\u001b[39;00m\n\u001b[32m    110\u001b[39m print_loss += loss\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Print progress\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, encoder, context_encoder, attack_clf, encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, batch_size, clip, max_length)\u001b[39m\n\u001b[32m     30\u001b[39m loss = F.binary_cross_entropy_with_logits(logits, labels)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Perform backpropatation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Clip gradients: gradients are modified in place\u001b[39;00m\n\u001b[32m     36\u001b[39m _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/gitclones/ConvoKit_Disputes/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/gitclones/ConvoKit_Disputes/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/gitclones/ConvoKit_Disputes/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Fix random state (affect native Python code only, does not affect PyTorch and hence does not guarantee reproducibility)\n",
    "random.seed(2019)\n",
    "\n",
    "# Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(\"Loading saved parameters...\")\n",
    "if not os.path.isfile(os.path.join(save_dir, \"model.tar\")):\n",
    "    raise RuntimeError(\"Pretrained model not found in {}\".format(os.path.join(save_dir, \"model.tar\", \"Have you tried running train_generative_model.py first?\")))\n",
    "checkpoint = torch.load(os.path.join(save_dir, \"model.tar\"), map_location=torch.device('cpu'))\n",
    "# If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.\n",
    "# To do so, replace the previous line with the following:\n",
    "# checkpoint = torch.load(\"model.tar\", map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "context_sd = checkpoint['ctx']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoders, decoder, and classifier...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# Initialize utterance and context encoders\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "context_encoder = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_encoder.load_state_dict(context_sd)\n",
    "# Initialize classifier\n",
    "attack_clf = SingleTargetClf(hidden_size, dropout)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "context_encoder = context_encoder.to(device)\n",
    "attack_clf = attack_clf.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "# Compute the number of training iterations we will need in order to achieve the number of epochs specified in the settings at the start of the notebook\n",
    "n_iter_per_epoch = len(train_pairs) // batch_size + int(len(train_pairs) % batch_size == 1)\n",
    "n_iteration = n_iter_per_epoch * finetune_epochs\n",
    "\n",
    "# Put dropout layers in train mode\n",
    "encoder.train()\n",
    "context_encoder.train()\n",
    "attack_clf.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=labeled_learning_rate)\n",
    "context_encoder_optimizer = optim.Adam(context_encoder.parameters(), lr=labeled_learning_rate)\n",
    "attack_clf_optimizer = optim.Adam(attack_clf.parameters(), lr=labeled_learning_rate)\n",
    "\n",
    "# Run training iterations, validating after every epoch\n",
    "print(\"Starting Training!\")\n",
    "print(\"Will train for {} iterations\".format(n_iteration))\n",
    "trainIters(voc, train_pairs, val_pairs, encoder, context_encoder, attack_clf,\n",
    "           encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,\n",
    "           n_iteration, batch_size, print_every, n_iter_per_epoch, clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na5gjZGE-KA0"
   },
   "source": [
    "## Part 7: run test set evaluation\n",
    "\n",
    "Now that we have successfully fine-tuned the model, we run it on the test set so that we can evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2551GR65-Wm5",
    "outputId": "154d7581-37a7-48e7-c203-9d3a97c472ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n",
      "Iteration: 1; Percent complete: 1.4%\n",
      "Iteration: 2; Percent complete: 2.9%\n",
      "Iteration: 3; Percent complete: 4.3%\n",
      "Iteration: 4; Percent complete: 5.8%\n",
      "Iteration: 5; Percent complete: 7.2%\n",
      "Iteration: 6; Percent complete: 8.7%\n",
      "Iteration: 7; Percent complete: 10.1%\n",
      "Iteration: 8; Percent complete: 11.6%\n",
      "Iteration: 9; Percent complete: 13.0%\n",
      "Iteration: 10; Percent complete: 14.5%\n",
      "Iteration: 11; Percent complete: 15.9%\n",
      "Iteration: 12; Percent complete: 17.4%\n",
      "Iteration: 13; Percent complete: 18.8%\n",
      "Iteration: 14; Percent complete: 20.3%\n",
      "Iteration: 15; Percent complete: 21.7%\n",
      "Iteration: 16; Percent complete: 23.2%\n",
      "Iteration: 17; Percent complete: 24.6%\n",
      "Iteration: 18; Percent complete: 26.1%\n",
      "Iteration: 19; Percent complete: 27.5%\n",
      "Iteration: 20; Percent complete: 29.0%\n",
      "Iteration: 21; Percent complete: 30.4%\n",
      "Iteration: 22; Percent complete: 31.9%\n",
      "Iteration: 23; Percent complete: 33.3%\n",
      "Iteration: 24; Percent complete: 34.8%\n",
      "Iteration: 25; Percent complete: 36.2%\n",
      "Iteration: 26; Percent complete: 37.7%\n",
      "Iteration: 27; Percent complete: 39.1%\n",
      "Iteration: 28; Percent complete: 40.6%\n",
      "Iteration: 29; Percent complete: 42.0%\n",
      "Iteration: 30; Percent complete: 43.5%\n",
      "Iteration: 31; Percent complete: 44.9%\n",
      "Iteration: 32; Percent complete: 46.4%\n",
      "Iteration: 33; Percent complete: 47.8%\n",
      "Iteration: 34; Percent complete: 49.3%\n",
      "Iteration: 35; Percent complete: 50.7%\n",
      "Iteration: 36; Percent complete: 52.2%\n",
      "Iteration: 37; Percent complete: 53.6%\n",
      "Iteration: 38; Percent complete: 55.1%\n",
      "Iteration: 39; Percent complete: 56.5%\n",
      "Iteration: 40; Percent complete: 58.0%\n",
      "Iteration: 41; Percent complete: 59.4%\n",
      "Iteration: 42; Percent complete: 60.9%\n",
      "Iteration: 43; Percent complete: 62.3%\n",
      "Iteration: 44; Percent complete: 63.8%\n",
      "Iteration: 45; Percent complete: 65.2%\n",
      "Iteration: 46; Percent complete: 66.7%\n",
      "Iteration: 47; Percent complete: 68.1%\n",
      "Iteration: 48; Percent complete: 69.6%\n",
      "Iteration: 49; Percent complete: 71.0%\n",
      "Iteration: 50; Percent complete: 72.5%\n",
      "Iteration: 51; Percent complete: 73.9%\n",
      "Iteration: 52; Percent complete: 75.4%\n",
      "Iteration: 53; Percent complete: 76.8%\n",
      "Iteration: 54; Percent complete: 78.3%\n",
      "Iteration: 55; Percent complete: 79.7%\n",
      "Iteration: 56; Percent complete: 81.2%\n",
      "Iteration: 57; Percent complete: 82.6%\n",
      "Iteration: 58; Percent complete: 84.1%\n",
      "Iteration: 59; Percent complete: 85.5%\n",
      "Iteration: 60; Percent complete: 87.0%\n",
      "Iteration: 61; Percent complete: 88.4%\n",
      "Iteration: 62; Percent complete: 89.9%\n",
      "Iteration: 63; Percent complete: 91.3%\n",
      "Iteration: 64; Percent complete: 92.8%\n",
      "Iteration: 65; Percent complete: 94.2%\n",
      "Iteration: 66; Percent complete: 95.7%\n",
      "Iteration: 67; Percent complete: 97.1%\n",
      "Iteration: 68; Percent complete: 98.6%\n",
      "Iteration: 69; Percent complete: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Fix random state for reproducibility\n",
    "random.seed(2019)\n",
    "\n",
    "# Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(\"Loading saved parameters...\")\n",
    "checkpoint = torch.load(os.path.join(save_dir, \"finetuned_model.tar\"))\n",
    "# If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.\n",
    "# To do so, replace the previous line with the following:\n",
    "checkpoint = torch.load(\"model.tar\", map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "context_sd = checkpoint['ctx']\n",
    "attack_clf_sd = checkpoint['atk_clf']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoders, decoder, and classifier...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# Initialize utterance and context encoders\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "context_encoder = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_encoder.load_state_dict(context_sd)\n",
    "# Initialize classifier\n",
    "attack_clf = SingleTargetClf(hidden_size, dropout)\n",
    "attack_clf.load_state_dict(attack_clf_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "context_encoder = context_encoder.to(device)\n",
    "attack_clf = attack_clf.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "context_encoder.eval()\n",
    "attack_clf.eval()\n",
    "\n",
    "# Initialize the pipeline\n",
    "predictor = Predictor(encoder, context_encoder, attack_clf)\n",
    "\n",
    "# Run the pipeline!\n",
    "forecasts_df = evaluateDataset(test_pairs, encoder, context_encoder, predictor, voc, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "lVK-1NWHEy7l",
    "outputId": "8b208593-4f96-444f-ad6c-cb84c0ffd88b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prediction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "89216df7-419f-479c-b856-6bcad668fb7b",
       "rows": [
        [
         "191149920.17102.17102",
         "1.0",
         "0.6942581534385681"
        ],
        [
         "192892110.19259.19259",
         "1.0",
         "0.8316590189933777"
        ],
        [
         "190192199.17060.17060",
         "0.0",
         "0.42608603835105896"
        ],
        [
         "192890095.19227.19227",
         "1.0",
         "0.7304735779762268"
        ],
        [
         "190192005.17004.17004",
         "0.0",
         "0.2717968821525574"
        ],
        [
         "192885632.19156.19156",
         "1.0",
         "0.7935836315155029"
        ],
        [
         "190191827.16918.16918",
         "0.0",
         "0.13992322981357574"
        ],
        [
         "192882222.19129.19129",
         "1.0",
         "0.6614545583724976"
        ],
        [
         "190191097.16843.16843",
         "0.0",
         "0.33537229895591736"
        ],
        [
         "192642615.19074.19074",
         "0.0",
         "0.41273948550224304"
        ],
        [
         "190190570.16705.16705",
         "0.0",
         "0.34341275691986084"
        ],
        [
         "192640416.19036.19036",
         "0.0",
         "0.4757799804210663"
        ],
        [
         "190189346.16645.16645",
         "1.0",
         "0.5651983618736267"
        ],
        [
         "203898053.13222.13222",
         "1.0",
         "0.9678473472595215"
        ],
        [
         "15838573.3653.3653",
         "0.0",
         "0.4323822259902954"
        ],
        [
         "192524064.18894.18894",
         "0.0",
         "0.395026296377182"
        ],
        [
         "188454964.16448.16448",
         "0.0",
         "0.2296895533800125"
        ],
        [
         "203897541.12640.12640",
         "1.0",
         "0.9601402282714844"
        ],
        [
         "390063750.29403.29403",
         "1.0",
         "0.7276061773300171"
        ],
        [
         "434000907.9886.9886",
         "1.0",
         "0.6595102548599243"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191149920.17102.17102</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.694258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192892110.19259.19259</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190192199.17060.17060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.426086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192890095.19227.19227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190192005.17004.17004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192885632.19156.19156</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.793584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190191827.16918.16918</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192882222.19129.19129</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190191097.16843.16843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192642615.19074.19074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190190570.16705.16705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192640416.19036.19036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190189346.16645.16645</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.565198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203898053.13222.13222</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15838573.3653.3653</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192524064.18894.18894</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188454964.16448.16448</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203897541.12640.12640</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390063750.29403.29403</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434000907.9886.9886</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.659510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prediction     score\n",
       "id                                         \n",
       "191149920.17102.17102         1.0  0.694258\n",
       "192892110.19259.19259         1.0  0.831659\n",
       "190192199.17060.17060         0.0  0.426086\n",
       "192890095.19227.19227         1.0  0.730474\n",
       "190192005.17004.17004         0.0  0.271797\n",
       "192885632.19156.19156         1.0  0.793584\n",
       "190191827.16918.16918         0.0  0.139923\n",
       "192882222.19129.19129         1.0  0.661455\n",
       "190191097.16843.16843         0.0  0.335372\n",
       "192642615.19074.19074         0.0  0.412739\n",
       "190190570.16705.16705         0.0  0.343413\n",
       "192640416.19036.19036         0.0  0.475780\n",
       "190189346.16645.16645         1.0  0.565198\n",
       "203898053.13222.13222         1.0  0.967847\n",
       "15838573.3653.3653            0.0  0.432382\n",
       "192524064.18894.18894         0.0  0.395026\n",
       "188454964.16448.16448         0.0  0.229690\n",
       "203897541.12640.12640         1.0  0.960140\n",
       "390063750.29403.29403         1.0  0.727606\n",
       "434000907.9886.9886           1.0  0.659510"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some of the outputs as a sanity-check\n",
    "forecasts_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_EMZ7-SKtEP"
   },
   "source": [
    "## Part 8: merge predictions back into corpus and evaluate\n",
    "\n",
    "Now that the hard part is done, all that is left to do is to evaluate the predictions. Since the predictions are in no particular order, we will first merge each prediction back into the source corpus, and then evaluate each conversation according to the order of utterances within that conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Vnjmtu-QLDVo"
   },
   "outputs": [],
   "source": [
    "# We will add a metadata entry to each test-set utterance signifying whether, at the time\n",
    "# that CRAFT saw the context *up to and including* that utterance, CRAFT forecasted the\n",
    "# conversation would derail. Note that in datasets where the actual toxic comment is\n",
    "# included (such as wikiconv), we explicitly do not show that comment to CRAFT (since\n",
    "# that would be cheating!), so that comment will not have an associated forecast.\n",
    "for convo in corpus.iter_conversations():\n",
    "    # only consider test set conversations (we did not make predictions for the other ones)\n",
    "    if convo.meta['split'] == \"test\":\n",
    "        for utt in convo.iter_utterances():\n",
    "            if utt.id in forecasts_df.index:\n",
    "                utt.meta['forecast_score'] = forecasts_df.loc[utt.id].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FYxW_AuWszqX",
    "outputId": "d478288b-55ae-4bc9-cb8c-f294a80f3174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6642857142857143\n"
     ]
    }
   ],
   "source": [
    "# Finally, we can use the forecast-annotated corpus to compute the forecast accuracy.\n",
    "# Though we have an individual forecast per utterance, ground truth is at the conversation level:\n",
    "# either a conversation derails or it does not. Thus, forecast accuracy is computed as follows:\n",
    "#   - True positives are cases that actually derail, for which the model made at least one positive forecast ANYTIME prior to derailment\n",
    "#   - False positives are cases that don't derail but for which the model made at least one positive forecast\n",
    "#   - False negatives are cases that derail but for which the model made no positive forecasts prior to derailment\n",
    "#   - True negatives are cases that don't derail, for which the model made no positive forecasts\n",
    "# Note that in the included datasets (wikiconv and cmv), by construction, all forecasts we obtained are forecasts made prior to derailment\n",
    "# (since these datasets end right before or right at the toxic comment). This simplifies  the computation of forecast metrics as we now \n",
    "# do not need to explicitly consider when a forecast was made. But if you are using a custom dataset where conversations continue past\n",
    "# the toxic comment, you will need to take that into account when evaluating.\n",
    "\n",
    "conversational_forecasts_df = {\n",
    "    \"convo_id\": [],\n",
    "    \"label\": [],\n",
    "    \"score\": [],\n",
    "    \"prediction\": []\n",
    "}\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == \"test\":\n",
    "        conversational_forecasts_df['convo_id'].append(convo.id)\n",
    "        conversational_forecasts_df['label'].append(int(convo.meta[label_metadata]))\n",
    "        forecast_scores = [utt.meta['forecast_score'] for utt in convo.iter_utterances() if 'forecast_score' in utt.meta]\n",
    "        conversational_forecasts_df['score'] = np.max(forecast_scores)\n",
    "        conversational_forecasts_df['prediction'].append(int(np.max(forecast_scores) > forecast_thresh))\n",
    "\n",
    "conversational_forecasts_df = pd.DataFrame(conversational_forecasts_df).set_index(\"convo_id\")\n",
    "print((conversational_forecasts_df.label == conversational_forecasts_df.prediction).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "_49Yaz2FIo9S",
    "outputId": "d1ae7b87-6973-41a1-e7aa-806d57990c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.6348, recall = 0.7738\n",
      "False positive rate = 0.4452380952380952\n",
      "F1 = 0.6974248927038625\n"
     ]
    }
   ],
   "source": [
    "# in addition to accuracy, we can also consider applying other metrics at the conversation level, such as precision/recall\n",
    "def get_pr_stats(preds, labels):\n",
    "    tp = ((labels==1)&(preds==1)).sum()\n",
    "    fp = ((labels==0)&(preds==1)).sum()\n",
    "    tn = ((labels==0)&(preds==0)).sum()\n",
    "    fn = ((labels==1)&(preds==0)).sum()\n",
    "    print(\"Precision = {0:.4f}, recall = {1:.4f}\".format(tp / (tp + fp), tp / (tp + fn)))\n",
    "    print(\"False positive rate =\", fp / (fp + tn))\n",
    "    print(\"F1 =\", 2 / (((tp + fp) / tp) + ((tp + fn) / tp)))\n",
    "\n",
    "get_pr_stats(conversational_forecasts_df.prediction, conversational_forecasts_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzBiI0dsW7WZ"
   },
   "source": [
    "## Part 9: model analysis: how early is early warning?\n",
    "\n",
    "The goal of CRAFT is to forecast outcomes in advance, but how far in advance does it typically make its prediction? Following the paper, we measure this in two ways: the number of *comments* between the first prediction and the actual derailment, and how much *elapsed time* that gap actually translates to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "8Qfvl9k8Xesh"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'forecast_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# now scan the utterances in order until we find the first derailment prediction (if any)\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(utts)):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mutts\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mforecast_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m > forecast_thresh:\n\u001b[32m     19\u001b[39m         comments_until_derail[convo.id] = derail_idx - idx\n\u001b[32m     20\u001b[39m         time_until_derail[convo.id] = utts[derail_idx].timestamp - utts[idx].timestamp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/gitclones/ConvoKit_Disputes/.venv/lib/python3.11/site-packages/convokit/model/convoKitMeta.py:37\u001b[39m, in \u001b[36mConvoKitMeta.__getitem__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# in DB mode, metadata field mutation would not be updated. (ex. mutating dict/list metadata fields)\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# we align MEM mode behavior and DB mode by making deepcopy of metadata fields, so mutation no longer\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# affect corpus metadata backend, but only acting on the copy of it.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     immutable_types = (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, immutable_types):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/gitclones/ConvoKit_Disputes/.venv/lib/python3.11/site-packages/convokit/model/backendMapper.py:179\u001b[39m, in \u001b[36mMemMapper.get_data\u001b[39m\u001b[34m(self, component_type, component_id, property_name, index)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m collection[component_id]\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollection\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomponent_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'forecast_score'"
     ]
    }
   ],
   "source": [
    "comments_until_derail = {} # store the \"number of comments until derailment\" metric for each conversation\n",
    "time_until_derail = {} # store the \"time until derailment\" metric for each conversation\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == \"test\" and convo.meta[label_metadata]:\n",
    "        # filter out the section header as usual\n",
    "        utts = [utt for utt in convo.iter_utterances() if not (corpus_name == 'wikiconv' and utt.meta['is_section_header'])]\n",
    "        if utt_label_metadata is not None:\n",
    "            # if utterances have individual toxicity labels, we assume that the last comment in the conversation\n",
    "            # is the one that is toxic (as in the case for wikiconv)\n",
    "            derail_idx = len(utts) - 1\n",
    "        else:\n",
    "            # otherwise, we assume that the toxic comment is not included and that derailment happens immediately\n",
    "            # after the last comment in the conversation\n",
    "            derail_idx = len(utts)\n",
    "        # now scan the utterances in order until we find the first derailment prediction (if any)\n",
    "        for idx in range(1, len(utts)):\n",
    "            if utts[idx].meta['forecast_score'] > forecast_thresh:\n",
    "                comments_until_derail[convo.id] = derail_idx - idx\n",
    "                time_until_derail[convo.id] = utts[derail_idx].timestamp - utts[idx].timestamp\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IFXn4LrMhJ8W",
    "outputId": "26611644-8c44-4380-8897-b0de6eece0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# compute some quick statistics about the distribution of the \"number of comments until derailment\" metric\n",
    "comments_until_derail_vals = np.asarray(list(comments_until_derail.values()))\n",
    "print(np.min(comments_until_derail_vals), np.max(comments_until_derail_vals), np.median(comments_until_derail_vals), np.mean(comments_until_derail_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7cTdzAuLhuHF",
    "outputId": "85df20c5-62e1-4d2c-8736-8432a65f55ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07555555555555556 0.07555555555555556 0.07555555555555556 0.07555555555555556\n"
     ]
    }
   ],
   "source": [
    "# compute some quick statistics about the distribution of the \"time until derailment\" metric\n",
    "# note that since timestamps are in seconds, we convert to hours by dividing by 3600, to make it more human readable\n",
    "time_until_derail_vals = np.asarray(list(time_until_derail.values())) / 3600\n",
    "print(np.min(time_until_derail_vals), np.max(time_until_derail_vals), np.median(time_until_derail_vals), np.mean(time_until_derail_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "_w3l6UxDiDAz",
    "outputId": "7de51fb0-dbb9-42f2-8d5f-18fcda28ab00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the distribution of \"number of comments until derailment\" as a histogram (reproducing Figure 4 from the paper)\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.hist(comments_until_derail_vals, bins=range(1, np.max(comments_until_derail_vals)), density=True)\n",
    "plt.xlim(1,10)\n",
    "plt.xticks(np.arange(1,10)+0.5, np.arange(1,10))\n",
    "plt.yticks(np.arange(0,0.25,0.05), np.arange(0,25,5))\n",
    "plt.xlabel(\"Number of comments elapsed\")\n",
    "plt.ylabel(\"% of conversations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CRAFT fine-tuning demo using ConvoKit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
